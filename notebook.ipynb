{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(1,1,5,3)\n",
    "x = torch.randn(5,5,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 5, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a - x\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = torch.nn.Embedding(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.2024,  0.2619,  0.3574],\n",
       "           [ 1.5205, -1.4985, -0.6328],\n",
       "           [-1.2650, -0.5821,  1.6800],\n",
       "           [ 0.6191,  0.0861, -2.1343],\n",
       "           [ 1.1509,  0.0057, -1.9844]]]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([0, 1, 2, 3, 4])[None,None,None,:]\n",
    "embed(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class PixelTokenizer(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, image_size, low=0.0, high=1.0, per_channel=False, num_channels=3, most_common_classes=None, dim=768):\n",
    "        super().__init__()\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.per_channel = per_channel\n",
    "        self.embed_table = nn.Embedding(vocab_size + 1, dim)\n",
    "        self.mask_token_id = vocab_size\n",
    "        self.num_channels = num_channels\n",
    "        self.vocab_size = vocab_size\n",
    "        self.h = self.w = image_size\n",
    "        self.hw = image_size * image_size\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, image_size * image_size * num_channels if per_channel else image_size * image_size,\n",
    "                                                        dim) * 0.005)\n",
    "        if per_channel:\n",
    "            classes = torch.linspace(low, high, vocab_size)[None,None,:]\n",
    "        else:\n",
    "            classes = torch.tensor(most_common_classes)[None,None,:,:]\n",
    "\n",
    "        self.register_buffer('classes', classes)\n",
    "\n",
    "    def dists(self, x):\n",
    "        classes = self.classes if len(self.classes.shape) == 4 else self.classes[...,None].repeat(1,1,1, self.num_channels)\n",
    "        if self.per_channel:\n",
    "            return (x.unsqueeze(-2) - classes).pow(2)\n",
    "        else:\n",
    "            return (x.unsqueeze(-2) - classes).pow(2).sum(-1, keepdim=True)\n",
    "\n",
    "    def decode(self, indices, h, w):\n",
    "        c = indices.shape[-1] // (h * w)\n",
    "        if c > 1:\n",
    "            indices = indices.reshape(-1, h * w, c)\n",
    "            indices = indices.reshape(-1, h * w, c).reshape(-1, h, w, c).permute(0, 3, 1, 2)\n",
    "            pixels = self.classes.squeeze()[indices]\n",
    "        else:\n",
    "            indices = indices.reshape(-1, h * w)\n",
    "            pixels = self.classes.squeeze()[indices, :]\n",
    "            c = pixels.shape[-1]\n",
    "            pixels = pixels.reshape(-1, h, w, c).permute(0, 3, 1, 2)\n",
    "\n",
    "        return pixels\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.view(b, c, h * w).transpose(1, 2)\n",
    "        indices = self.dists(x).argmin(-2)\n",
    "        indices = indices.reshape(b, h * w * indices.shape[-1])\n",
    "        return indices\n",
    "\n",
    "    def to_embs(self, indices):\n",
    "        b, hwc = indices.shape\n",
    "        c = hwc // (self.hw)\n",
    "        embeds = self.embed_table(indices) + self.pos_embed.expand(b, -1, -1)\n",
    "        # b, hw, c * dim -> b, c * dim, h, w\n",
    "        # embeds = embeds.permute(0, 2, 1).reshape(b, -1, self.h, self.w * 3)\n",
    "        return embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_classes = [\n",
    "    [0.0, 0.5, 0.3],\n",
    "    [0.8, 0.2, 0.1],\n",
    "    [0.2, 0.1, 0.9],\n",
    "    [0.1, 0.9, 0.2],\n",
    "]\n",
    "\n",
    "tokenizer = PixelTokenizer(3, 32, most_common_classes=most_common_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tokenizer.encode(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = tokenizer.decode(indices, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import safetensors\n",
    "import torch\n",
    "import random\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import faiss\n",
    "\n",
    "def open_weights(path):\n",
    "    try: # if \".safetensors\" in path:\n",
    "        state_dict = {}\n",
    "        with safetensors.safe_open(path, \"pt\") as f:\n",
    "            for k in f.keys():\n",
    "                state_dict[k] = f.get_tensor(k)\n",
    "    except:\n",
    "        state_dict = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def get_kmeans_clusters(latents=None, dataset_name=\"cifar\", k=256, image_size=32, num_images=2000, verbose=True, niter=100):\n",
    "    transform = T.Compose(\n",
    "        [T.ToTensor(),\n",
    "         T.Resize(image_size),\n",
    "         T.CenterCrop(image_size),]\n",
    "    )\n",
    "\n",
    "    dataset_classes = {\n",
    "        \"cifar\": torchvision.datasets.CIFAR10,\n",
    "        \"celeb-a\": torchvision.datasets.CelebA,\n",
    "        \"flowers102\": torchvision.datasets.Flowers102,\n",
    "    }\n",
    "    dataset_cls = dataset_classes[dataset_name]\n",
    "    dataset = dataset_cls(root='./data', #split='train',\n",
    "                                 download=True, transform=transform)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        shuffle=True,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "         pin_memory=False\n",
    "    )\n",
    "\n",
    "    images = []\n",
    "    for i, x in enumerate(dataloader):\n",
    "        images.extend(x[0].chunk(x[0].size(0)))\n",
    "        if len(images) >= num_images:\n",
    "            break\n",
    "    images = torch.cat(images, 0).permute(0, 2, 3, 1).reshape(-1, 3).numpy()\n",
    "    c = 3 if dataset_name is None else latents.shape[-1]\n",
    "        \n",
    "    kmeans = faiss.Kmeans(c, k, niter=niter, verbose=verbose)\n",
    "    kmeans.train(images)\n",
    "\n",
    "    return kmeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Sampling a subset of 1048576 / 2097152 for training\n",
      "Clustering 1048576 points in 3D to 4096 clusters, redo 1 times, 100 iterations\n",
      "  Preprocessing in 0.07 s\n",
      "  Iteration 99 (17.96 s, search 11.95 s): objective=289.303 imbalance=1.530 nsplit=0       \n"
     ]
    }
   ],
   "source": [
    "kmeans = get_kmeans_clusters(\"cifar\", k=4096, image_size=32, num_images=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6780388cd0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "centroids = torch.from_numpy(kmeans.centroids)[:,None,:]\n",
    "centroids = centroids[:100].repeat_interleave(100,1)\n",
    "plt.imshow(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
